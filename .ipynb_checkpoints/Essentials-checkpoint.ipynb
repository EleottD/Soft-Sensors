{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c5f119-8623-4818-9367-0b8427fa104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from abc import ABC\n",
    "from abc import abstractmethod\n",
    "from typing import List, Type\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c71e7-534e-4931-914f-d24c6e09bb06",
   "metadata": {},
   "source": [
    "# Определение основных функций подготовки данных и визуализации для создания моделей Виртуальных Анализаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10c8694-35b1-4573-80e5-5b9c8b3afde0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SoftSensor(ABC):    \n",
    "    @abstractmethod\n",
    "    def __init__(self, name: str):\n",
    "        self.__model = None\n",
    "        self.__name = name\n",
    "\n",
    "    @abstractmethod\n",
    "    def prepocessing(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def postprocessing(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate_model(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def __str__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.__model\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.__model = model\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.__name\n",
    "\n",
    "    def set_name(self, name):\n",
    "        self.__name = name\n",
    "\n",
    "    def test(self, x_test: np.ndarray, y_test: np.ndarray, metric):\n",
    "        if len(x_test.shape) != 2:\n",
    "            raise AttributeError('Wrong data shape X')\n",
    "        if y_test.shape[1] != 1 and len(y_test.shape) != 2:\n",
    "            raise AttributeError('Wrong data shape Y') \n",
    "\n",
    "        try:\n",
    "            x_preproc_values = self.prepocessing(x_test)\n",
    "            y_preproc_values = self.prepocessing(y_test)\n",
    "        except BaseException as err:\n",
    "            print('Prepocessing error', err)\n",
    "            raise err\n",
    "            \n",
    "        try:\n",
    "            pred_values = self.evaluate_model(x_preproc_values)\n",
    "        except BaseException as err:\n",
    "            print('Model evaluation error', err)\n",
    "            raise err\n",
    "\n",
    "        try:\n",
    "            metric_value = metric.evaluate(pred_values, y_preproc_values)\n",
    "        except BaseException as err:\n",
    "            print('Metric evaluation error', err)\n",
    "            raise err\n",
    "\n",
    "        try:\n",
    "            post_values = self.postprocessing(pred_values)\n",
    "        except BaseException as err:\n",
    "            print('Postprocessing error', err)\n",
    "            raise err\n",
    "            \n",
    "        if type(post_values) != np.ndarray:\n",
    "            raise TypeError('Wrong data type after postrocessing')\n",
    "        if post_values.shape[1] != 1 and len(post_values.shape) != 2:\n",
    "            raise ValueError('Wrong data shape')\n",
    "\n",
    "        return post_values, metric_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57903b57-5a78-4ef9-97be-0708a0d2c65b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MetricTemplate(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self, name):\n",
    "        if type(name) is not str:\n",
    "            raise AttributeError('Wrong name')\n",
    "        self.__name = name\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self):\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, y_pred, y_real):\n",
    "        try:\n",
    "            value = self.__call__(y_pred, y_real)\n",
    "        except BaseException as err:\n",
    "            print('Metric evaluation error')\n",
    "            raise err\n",
    "        if type(value) != float and type(value) != np.float64:\n",
    "            raise ValueError('Wrong datatype from metric')\n",
    "        if value.size != 1:\n",
    "            raise ValueError('Wrong data shape from metric')\n",
    "        return value\n",
    "        \n",
    "    def get_name(self):\n",
    "        return self.__name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca82f5d5-0301-4765-af11-a370711c96fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Visualizer():\n",
    "\n",
    "    def __init__(self, x, y, timestamps, metrics: List[Type[MetricTemplate]], name):\n",
    "    \n",
    "        try:\n",
    "            self.x_test = np.array(x, dtype=np.float64)\n",
    "            self.y_real = np.array(y, dtype=np.float64)\n",
    "        except BaseException as err:\n",
    "            print('Data transform error')\n",
    "            raise err\n",
    "        self.timestamps = timestamps\n",
    "        self.metrics = metrics\n",
    "        self.name = name\n",
    "        \n",
    "\n",
    "    def visualize(self, models: List[Type[SoftSensor]], verbose=True, all=True, each=True):\n",
    "        metric_num = len(self.metrics)\n",
    "        metric_dict = {}\n",
    "        if verbose:\n",
    "            for metric in self.metrics:\n",
    "                metric_values = []\n",
    "                for model in models:\n",
    "                    _, metric_value = model.test(self.x_test, self.y_real, metric)\n",
    "                    metric_values.append(metric_value)\n",
    "                metric_dict[metric.get_name()] = metric_values\n",
    "            index = []\n",
    "            for model in models:\n",
    "                index.append(model.get_name())\n",
    "            df_metric = pd.DataFrame(data=metric_dict, index=index)\n",
    "            print(df_metric)\n",
    "\n",
    "        results = {}\n",
    "        results['From Lab'] = self.y_real\n",
    "        for model in models:\n",
    "            model_pred, _ = model.test(self.x_test, self.y_real, self.metrics[0])\n",
    "            results[model.get_name()] = np.squeeze(model_pred)\n",
    "\n",
    "        for name, data in results.items():\n",
    "            plt.plot(self.timestamps, data, linestyle='', marker=\".\", label=name)\n",
    "        plt.title(self.name)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # res_df = pd.DataFrame(data=results, index=self.timestamps)\n",
    "\n",
    "        # if all:\n",
    "        #     plt.plot()\n",
    "            \n",
    "\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c1d6cc-f8e6-4c84-b56f-72915f5eb78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95aa9f07-70ff-4d0a-84fb-7afad4bd0fb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MSE(MetricTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('MSE')\n",
    "\n",
    "    def __call__(self, y_pred, y_real):\n",
    "        return ((y_pred-y_real)**2).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91041dd-5102-4621-bd01-8d3eecb2816d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class R2Metric(MetricTemplate):\n",
    "    def __init__(self):\n",
    "        super().__init__('Coefficient of determination')\n",
    "\n",
    "    def __call__(self, y_pred, y_real):\n",
    "        return sklearn.metrics.r2_score(y_real, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda2e4a-655b-4f4b-92d9-b6cb7a671cba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
